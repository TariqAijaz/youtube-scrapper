{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d62a41-8751-48a4-ae43-0195a3a1f2f2",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3929306-6ed6-4a46-929e-b48e3bec27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pytube import YouTube\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from pprint import pprint\n",
    "from tabulate import tabulate\n",
    "\n",
    "import speech_recognition as sr\n",
    "from moviepy.editor import VideoFileClip\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from docx import Document\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from functools import partial, reduce\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import isodate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c3023-5b2c-42b9-bac4-41674d8996c1",
   "metadata": {},
   "source": [
    "### Get API Key - Initialize YouTube Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4f00d-f080-461f-b4ff-3628916c077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your API Key - Authorize credentials from Google Cloud Console - https://console.cloud.google.com/\n",
    "# API_KEY = ''\n",
    "API_KEY = ''\n",
    "\n",
    "# Create a YouTube Data API service object\n",
    "youtube = build('youtube','v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5132195-9a4e-46e6-9fb0-01d368f5ae92",
   "metadata": {},
   "source": [
    "### About Youtube Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2729f-8fd5-484d-a495-62353b90b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "channelId = 'UCUMZ7gohGI9HcU9VNsr2FJQ' \n",
    "\n",
    "about_search_request = youtube.channels().list(\n",
    "        part=\"snippet, statistics, contentDetails\",\n",
    "        id = channelId\n",
    ")\n",
    "\n",
    "about_search_response = about_search_request.execute()\n",
    "    \n",
    "print(json.dumps(about_search_response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6154d0-a72f-485b-a36a-55d51f2b864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_list = []\n",
    "# i = 0\n",
    "for item in about_search_response['items']:\n",
    "    channel_id = item['id']\n",
    "    title = item['snippet']['title']\n",
    "    viewCount = item['statistics']['viewCount']\n",
    "    subscriberCount = item['statistics']['subscriberCount']\n",
    "    videoCount = item['statistics']['videoCount']\n",
    "    \n",
    "    channels_list.append({\n",
    "        # \"S.NO\": i,\n",
    "        \"channel_id\": channel_id,\n",
    "        \"title\": title,\n",
    "        \"viewCount\": int(viewCount),\n",
    "        \"subscriberCount\": int(subscriberCount), \n",
    "        \"videoCount\": int(videoCount), \n",
    "      # \"view_count\": view_count  # Might be None if data unavailable\n",
    "    })\n",
    "\n",
    "    # i = i + 1\n",
    "\n",
    "# for i, video in enumerate(videos_list):\n",
    "    # print(f\"{i+1}. {video['title']} (by {video['description']})\")\n",
    "\n",
    "channels_list_df = pd.DataFrame(channels_list)\n",
    "channels_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768591d6-d657-49be-bb71-457bd8e14bd6",
   "metadata": {},
   "source": [
    "### Search Video List Using Channel Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44e496-6580-4301-ba59-8d7589a9b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for videos based on the Channel Id\n",
    "\n",
    "# Bloomberg Originals\n",
    "channelId = 'UCUMZ7gohGI9HcU9VNsr2FJQ' \n",
    "\n",
    "search_request = youtube.search().list(\n",
    "    part=\"snippet\",\n",
    "    maxResults = 50,\n",
    "    channelId = channelId,\n",
    "    type=\"video\"\n",
    ")\n",
    "\n",
    "search_response = search_request.execute()\n",
    "\n",
    "print(json.dumps(search_response, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2802f-b4db-4cbc-b629-e2843d5145d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract video information from search results\n",
    "videos_list = []\n",
    "# i = 0\n",
    "for item in search_response['items']:\n",
    "    video_id = item['id'].get('videoId')\n",
    "    # video_id = item['id']['videoId']\n",
    "    title = item['snippet']['title']\n",
    "    channel_title = item['snippet']['channelTitle']\n",
    "    description = item['snippet']['description']\n",
    "    publishedAt = item['snippet']['publishedAt']\n",
    "    \n",
    "    videos_list.append({\n",
    "        # \"S.NO\": i,\n",
    "        \"video_id\": video_id,\n",
    "        \"title\": title,\n",
    "        \"channel_title\": channel_title,\n",
    "        \"description\": description, \n",
    "        \"publishedAt\": publishedAt, \n",
    "      # \"view_count\": view_count  # Might be None if data unavailable\n",
    "    })\n",
    "\n",
    "    # i = i + 1\n",
    "\n",
    "# for i, video in enumerate(videos_list):\n",
    "    # print(f\"{i+1}. {video['title']} (by {video['description']})\")\n",
    "\n",
    "videos_list_df = pd.DataFrame(videos_list)\n",
    "videos_list_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2350e54-459c-4be1-8a1b-0e82698be0ac",
   "metadata": {},
   "source": [
    "### Extract Video Ids From Searched Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012eecf-2305-4164-bcce-5297332bfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [items['video_id'] for items in videos_list]\n",
    "print(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d84ef-6df2-4017-8ae3-3019d6bdd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search duration of videos\n",
    "\n",
    "content_details_request = youtube.videos().list(\n",
    "    part=\"contentDetails\",\n",
    "    maxResults = 50,\n",
    "    id = ','.join(video_ids)\n",
    ")\n",
    "\n",
    "content_details_response = content_details_request.execute()\n",
    "\n",
    "print(json.dumps(content_details_response, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7d9c7-8bcc-4c62-bfff-bef12b0ce5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract video information from search results\n",
    "videos_duration_list = []\n",
    "i = 0\n",
    "for item in content_details_response['items']:\n",
    "    video_id = item['id']\n",
    "    duration = isodate.parse_duration(item['contentDetails']['duration']).total_seconds()\n",
    "    dimension = item['contentDetails']['dimension']\n",
    "    definition = item['contentDetails']['definition']\n",
    "    projection = item['contentDetails']['projection']\n",
    "    \n",
    "    videos_duration_list.append({\n",
    "        # \"S.NO\": i,\n",
    "        \"video_id\": video_id,\n",
    "        \"duration (sec)\": duration,\n",
    "        \"dimension\": dimension,\n",
    "        \"definition\": definition, \n",
    "        \"projection\": projection, \n",
    "      # \"view_count\": view_count  # Might be None if data unavailable\n",
    "    })\n",
    "\n",
    "    # i = i + 1\n",
    "\n",
    "# for i, video in enumerate(videos_list):\n",
    "    # print(f\"{i+1}. {video['title']} (by {video['description']})\")\n",
    "\n",
    "videos_duration_list_df = pd.DataFrame(videos_duration_list)\n",
    "videos_duration_list_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddc4b1-e13e-4043-bf3a-3eb6afd3b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search stats of videos\n",
    "\n",
    "stats_request = youtube.videos().list(\n",
    "    part = 'statistics',\n",
    "    maxResults = 50,\n",
    "    id = ','.join(video_ids)\n",
    ")\n",
    "\n",
    "stats_response = stats_request.execute()\n",
    "\n",
    "print(json.dumps(stats_response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c23dd9-eeaa-4f14-8ba5-c2b651a2b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_stats_list = []\n",
    "\n",
    "for item in stats_response['items']:\n",
    "    videos_id = item['id']\n",
    "    view_count = item['statistics']['viewCount']\n",
    "    like_count = item['statistics']['likeCount']\n",
    "    favorite_count = item['statistics'].get('favoriteCount')\n",
    "    comment_count = item['statistics'].get('commentCount')\n",
    "    # view_count = item.get('snippet', {}).get('thumbnails', {}).get('default', {}).get('viewCount', None)  # Handle potential missing data\n",
    "\n",
    "    videos_stats_list.append({\n",
    "        \"video_id\": videos_id,\n",
    "        \"view_count\": view_count,\n",
    "        \"like_count\": like_count, \n",
    "        \"favorite_count\": favorite_count, \n",
    "        \"comment_count\": comment_count, \n",
    "    })\n",
    "\n",
    "videos_stats_list_df = pd.DataFrame(videos_stats_list)\n",
    "videos_stats_list_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73563181-fe7e-4454-b213-0fef2007e6aa",
   "metadata": {},
   "source": [
    "### Sentiment Analysis - Extracting Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fdda38-0779-4dff-b8ec-43d794ebef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comments functions using video id\n",
    "\n",
    "def get_comments(video_id):\n",
    "    videos_comments_list = []\n",
    "    try:\n",
    "        comments_request = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId = video_id,\n",
    "            textFormat='plainText'\n",
    "        )\n",
    "\n",
    "        comments_response = comments_request.execute()\n",
    "        # print(json.dumps(comments_response, indent=4))\n",
    "        \n",
    "        for comment in comments_response['items']:\n",
    "            video_id = comment['snippet']['topLevelComment']['snippet']['videoId']\n",
    "            text = comment['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "            videos_comments_list.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"text\": text,\n",
    "            })\n",
    "    \n",
    "        return videos_comments_list\n",
    "        \n",
    "    except HttpError as e:\n",
    "        print(f'Error fetching comments for Video ID {video_id}: {e}')\n",
    "        videos_comments_list.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"text\": 'Disabled Comments',\n",
    "            })\n",
    "        return videos_comments_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1ae79-affc-4a52-94d7-5a7d24f6222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch comments for each video ID\n",
    "all_comments = {}\n",
    "for video_id in video_ids:\n",
    "    comments = get_comments(video_id)\n",
    "    all_comments[video_id] = comments\n",
    "\n",
    "comments_list = []\n",
    "\n",
    "for video_id, comments in all_comments.items():\n",
    "    # print(f'Comments for Video ID {video_id}:')\n",
    "    if comments:\n",
    "        for comment_text in comments:\n",
    "            # print(comment_text['text'])\n",
    "            comments_list.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"comment\": comment_text['text'],\n",
    "            })\n",
    "    else:\n",
    "        # print('No comments found.')\n",
    "        comments_list.append({\n",
    "            \"video_id\": video_id,\n",
    "            \"comment\": 'No comments',\n",
    "        })\n",
    "    # print()\n",
    "\n",
    "comments_list_df = pd.DataFrame(comments_list)\n",
    "comments_list_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e157339-0a37-4ca9-a656-1cd187d0f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(comments_list_df['comment'])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a953752-63aa-4765-9195-83a5dfe3e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textblob\n",
    "blob = TextBlob(text)\n",
    "polarity = blob.sentiment.polarity\n",
    "subjectivity = blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f50139-8efc-4f25-8c3a-d0953a6e54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine sentiment label\n",
    "if polarity>0:\n",
    "    sentiment_label='positive'\n",
    "elif polarity<0:\n",
    "    sentiment_label='negative'\n",
    "else:\n",
    "    sentiment_label='neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f1f5a-fc68-4894-9d9a-7af2bb0f2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(['polarity','Subjectivity'],[polarity,subjectivity],color=['green','blue'])\n",
    "plt.title('Sentiment analysis')\n",
    "plt.ylabel('Score')\n",
    "#plt.ylim(-1,1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y',linestyle='--',alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Polarity: {polarity:.2f} (Label: {sentiment_label})\")\n",
    "print(f\"Subjectivity: {subjectivity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa4be0-7b5c-4d42-adba-040a0d81d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "new_words = ['comments','really','love','want','much','will', 'now', 'make', 'lol', 'und', 'thing', 't', 'even', 'still', 'u', 's']\n",
    "new_stopwords = stopwords.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1928d0d-6587-4381-9617-61574bc287de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud\n",
    "wordcloud = WordCloud(max_words = 50, stopwords = new_stopwords, width=800, height=400, background_color=\"white\").generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud Example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16bd5f-9961-44b3-8dd7-51f6e819746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.youtube.com/watch?v=Fpn1imb9qZg&ab_channel=Coldplay\"\n",
    "# yt = YouTube(url)\n",
    "# yt.streams.get_by_resolution('2160p')\n",
    "# yt.streams.first().download()\n",
    "# print(\"Download Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c18f2-835d-46c4-a652-e70d31dc8972",
   "metadata": {},
   "source": [
    "### Concatenating All the Datasets Togeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01995cd4-e9d9-4ba6-a9d3-b3f987eca3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos_list_df\n",
    "# videos_stats_list_df\n",
    "# videos_duration_list_df\n",
    "\n",
    "data_frames = [videos_list_df, videos_stats_list_df, videos_duration_list_df]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left, right, on=['video_id'], how='left'), data_frames)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19425f80-5620-4fe3-b453-4b9756367d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by column \"view_count\" to get Top 5 Videos\n",
    "df_merged = df_merged.sort_values(by=['view_count'], ascending=False)\n",
    "top_5_videos_df = df_merged[['title','description','view_count','like_count','comment_count']].head(5)\n",
    "top_5_videos_df.to_csv(\"top_5_videos_df.csv\", index=False)\n",
    "top_5_videos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927f4b1-e103-4cbb-b85a-27d982d00d97",
   "metadata": {},
   "source": [
    "### Visualizing The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d9a2c-17e8-4e2f-a918-c13169daa63b",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606af98b-e15f-4135-b21a-c02c80c18108",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "df_merged['publishedAt'] = pd.to_datetime(df_merged['publishedAt'])\n",
    "df_merged['publishedAt'] = pd.to_numeric(df_merged['publishedAt'])\n",
    "mask = np.triu(np.ones_like(df_merged[['duration (sec)', 'view_count', 'like_count', 'comment_count', 'publishedAt']].corr(),dtype=bool))\n",
    "# sns.heatmap(df_merged[['duration (sec)', 'view_count']].corr(), annot=True, fmt='.2f',cmap='BrBG')\n",
    "sns.heatmap(df_merged[['duration (sec)', 'view_count', 'like_count', 'comment_count', 'publishedAt']].corr(), annot=True, mask=mask, fmt='.2f',cmap='BrBG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5812995-8d56-4b7a-a3ca-82dfef81f360",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c78dcc-804e-419a-802f-a52c536024dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Bloomberg Originals Video Duration Using Histogram\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(df_merged['duration (sec)'], edgecolor=\"black\")\n",
    "\n",
    "plt.title('Bloomberg Originals Video Duration Distribution', size=14, fontweight=\"bold\")\n",
    "plt.xlabel('Duration', fontsize=10)\n",
    "plt.ylabel('Count', fontsize=10)\n",
    "plt.grid(True)\n",
    "# plt.savefig('Tesla stock price histogram.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d2587-690d-412c-baed-d24a69913f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Bloomberg Originals View Count Using Boxplot\n",
    "\n",
    "df_merged['view_count'] = pd.to_numeric(df_merged['view_count'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=df_merged, x=\"view_count\", whis=(0, 100))\n",
    "plt.title('Bloomberg Originals View Count Boxplot', size=14, fontweight=\"bold\")\n",
    "plt.xlabel('View Count (M)', fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa4167-65d8-42f7-a841-15d10a5dc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Bloomberg Originals Like Count Using Boxplot\n",
    "\n",
    "df_merged['like_count'] = pd.to_numeric(df_merged['like_count'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=df_merged, x=\"like_count\", whis=(0, 100))\n",
    "plt.title('Bloomberg Originals Like Count Boxplot', size=14, fontweight=\"bold\")\n",
    "plt.xlabel('Like Count', fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8817a4-c3ce-44d3-a69e-ea7530a742e8",
   "metadata": {},
   "source": [
    "### Correlation Between Like Count, View Count & Duration of Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3be4f-bf8b-47b3-ae58-50b9a06d5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration vs Like Count Using Scatter plot\n",
    "\n",
    "df_merged['like_count'] = pd.to_numeric(df_merged['like_count'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(data=df_merged, x=\"duration (sec)\", y=\"like_count\", palette=\"deep\", sizes=(20, 200), legend=\"full\")\n",
    "plt.title('Duration vs Like Count', size=14, fontweight=\"bold\")\n",
    "plt.xlabel('Duration (sec)', fontsize=10)\n",
    "plt.ylabel('Like Count', fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a58712-da64-41c7-a9b5-9106a145bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration vs View Count Using Scatter plot\n",
    "\n",
    "df_merged['view_count'] = pd.to_numeric(df_merged['view_count'])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(data=df_merged, x=\"duration (sec)\", y=\"view_count\", palette=\"deep\", sizes=(20, 200), legend=\"full\")\n",
    "plt.title('Duration vs View Count', size=14, fontweight=\"bold\")\n",
    "plt.xlabel('Duration (sec)', fontsize=10)\n",
    "plt.ylabel('View Count', fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac5305-098f-411b-a1a3-bbaae2b128dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
